{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gensim\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Importing from my files\n",
    "from entity import argmax, log_sum_exp, BiLSTM_CRF\n",
    "from dataloader import get_data\n",
    "from intent import IntentBiLSTM, get_predicted_intent, get_ICA\n",
    "from shared import SharedBiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/word2vecmodel')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, int_dict, entity_dict, n_intents = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "entity_dict[START_TAG] = list(entity_dict.values())[-1]+1\n",
    "entity_dict[STOP_TAG] = list(entity_dict.values())[-1]+1\n",
    "tag_to_ix = entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "N_INTENTS = n_intents\n",
    "EPOCHS = 10\n",
    "val_samples =  len(val_loader)\n",
    "n_samples = len(train_loader)\n",
    "batch_size = 1\n",
    "n_iterations = math.ceil(n_samples/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskWord2vec(nn.Module):\n",
    "    def __init__(self, embedding_size, SharedModel, IntentModel, EntityModel):\n",
    "        super().__init__()\n",
    "        self.SharedModel = SharedModel\n",
    "        self.IntentModel = IntentModel\n",
    "        self.EntityModel = EntityModel \n",
    "        \n",
    "    def forward(self, x, entities=None, Train=False):\n",
    "        x = self.SharedModel(x)\n",
    "        x_i = self.IntentModel(x)  # This will return intent\n",
    "        if(Train):\n",
    "            x_e = self.EntityModel.neg_log_likelihood(x, entities)  # This will return entity loss\n",
    "        else:\n",
    "            x_e = self.EntityModel(x) # Returns score and tag sequence\n",
    "        return x_i, x_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for the embedding model\n",
    "\n",
    "def get_embedding_model():\n",
    "    weights_path = cached_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\")\n",
    "    options_path = cached_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\")\n",
    "    elmo = Elmo(options_path, weights_path, num_output_representations=1, dropout=0) # set requires_grad=True if we want to finetune\n",
    "    return elmo\n",
    "\n",
    "def get_elmo_embedding(sentence):\n",
    "    sentence = [sentence]  # batch size = 1\n",
    "    character_ids = batch_to_ids(sentence)\n",
    "    embeddings = EmbeddingModel(character_ids)\n",
    "    return embeddings['elmo_representations'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing checkpoints\n",
    "def save_checkpoint_best(epoch, model):\n",
    "    print(\"Saving best model\")\n",
    "    PATH = \"/workspace/data/Dhruv/pytorch/BestModel/best_model_\"+str(epoch)+\".pt\"\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer):  # Saving model in a way so we can load and start training again\n",
    "    PATH = \"C:/Users/dhruv/Desktop/ASP sem 1/Capstone/Models/FinalWord2vecModels/model_\"+str(epoch)+\".pt\"\n",
    "    print(\"Saving model\")\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EntityModel = BiLSTM_CRF(tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
    "IntentModel = IntentBiLSTM(N_INTENTS, EMBEDDING_DIM, HIDDEN_DIM, batch_size).to(device)\n",
    "EmbeddingModel = get_embedding_model() # Make this non trainable\n",
    "SharedModel = SharedBiLSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_size).to(device)\n",
    "model = MultiTaskWord2vec(EMBEDDING_DIM, SharedModel, IntentModel, EntityModel).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "tr_loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexample = iter(val_loader)\\nexample_q, example_s, example_i = example.next()\\nexample_q = torch.from_numpy(EmbeddingModel.wv[example_q]) # Here assuming sentence is already tokenized\\nexample_q = torch.unsqueeze(example_q, 1).to(device)\\nexample_s = torch.tensor([tag_to_ix[t] for t in example_s], dtype=torch.long)\\nwriter.add_graph(model, (example_q.to(device), example_i.to(device), example_s.to(device)))\\nwriter.close()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "example = iter(val_loader)\n",
    "example_q, example_s, example_i = example.next()\n",
    "example_q = torch.from_numpy(EmbeddingModel.wv[example_q]) # Here assuming sentence is already tokenized\n",
    "example_q = torch.unsqueeze(example_q, 1).to(device)\n",
    "example_s = torch.tensor([tag_to_ix[t] for t in example_s], dtype=torch.long)\n",
    "writer.add_graph(model, (example_q.to(device), example_i.to(device), example_s.to(device)))\n",
    "writer.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model():\n",
    "    \n",
    "    least_val_loss = math.inf\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        beg_time = time.time() #To calculate time taken for each epoch\n",
    "        train_loss = 0.0\n",
    "        entity_score = 0.0\n",
    "        entity_f1 = 0.0\n",
    "        intent_ICA = 0.0\n",
    "        \n",
    "        for i, (sentence, tags, intent) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            sentence_in = get_elmo_embedding(sentence)   # Here assuming sentence is already tokenized\n",
    "            sentence_in = torch.unsqueeze(sentence_in, 1).to(device) \n",
    "            targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long).to(device)\n",
    "            intent = intent.to(device)\n",
    "            # Forward pass\n",
    "            pred_i, loss_e = model(sentence_in, entities=targets, Train=True)\n",
    "            CrossEntropyIntentLoss = torch.sum(-intent * torch.log(pred_i[0]))  # Cross entropy loss\n",
    "            loss = CrossEntropyIntentLoss + loss_e/10 # Weighed equally\n",
    "            loss.backward()\n",
    "            # Update gradients\n",
    "            optimizer.step()\n",
    "            # Get training loss\n",
    "            train_loss += loss.item()\n",
    "        tr_loss_log.append(train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (sentence, tags, intent) in enumerate(val_loader):\n",
    "                optimizer.zero_grad()\n",
    "                sentence_in = get_elmo_embedding(sentence) # Here assuming sentence is already tokenized\n",
    "                sentence_in = torch.unsqueeze(sentence_in, 1).to(device) \n",
    "                targets = list([tag_to_ix[t] for t in tags])\n",
    "                intent = intent.float().to(device)\n",
    "                pred_i, (entity_score_1, pred_entities) = model(sentence_in)\n",
    "                intent_ICA_1 = get_ICA(pred_i[0], intent) # This will give us the intent classification accuracy\n",
    "                entity_f1_1 = f1_score(targets, pred_entities, average='micro')\n",
    "                entity_score += entity_score_1\n",
    "                entity_f1 += entity_f1_1\n",
    "                intent_ICA += intent_ICA_1\n",
    "        model.train()\n",
    "      \n",
    "        # Saving checkpoints\n",
    "        save_checkpoint(epoch+1, model, optimizer)\n",
    "        '''\n",
    "        if(val_loss < least_val_loss):\n",
    "            save_checkpoint_best(epoch+1, model)\n",
    "            least_val_loss = val_loss\n",
    "        '''\n",
    "          \n",
    "        end_time = time.time()\n",
    "        print('Epoch: {:.0f}/{:.0f}, Time: {:.0f}m {:.0f}s, Train_Loss: {:.4f}, Val_ICA: {:.4f}, Val_entity_score: {:.4f}, Val_entity_F1_score: {:.4f}'.format(\n",
    "            epoch+1, EPOCHS, (end_time-beg_time)//60, (end_time-beg_time)%60, train_loss, intent_ICA/val_samples, entity_score/val_samples, entity_f1/val_samples))\n",
    "        writer.add_scalar('Training_loss', train_loss, (epoch+1))\n",
    "        writer.add_scalar('Val_ICA', intent_ICA/val_samples, (epoch+1))\n",
    "        writer.add_scalar('Val_entity_F1_score', entity_f1/val_samples, (epoch+1))\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"C:/Users/dhruv/Desktop/ASP sem 1/Capstone/Models/FinalElmoNoFTModels/model_8.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_ICA: 0.9586, Test_entity_score: 111.2955, Test_entity_F1_score: 0.9725\n"
     ]
    }
   ],
   "source": [
    "test_samples =  len(test_loader)\n",
    "entity_score = 0.0\n",
    "entity_f1 = 0.0\n",
    "intent_ICA = 0.0\n",
    "with torch.no_grad():\n",
    "    for i, (sentence, tags, intent) in enumerate(test_loader):\n",
    "        sentence_in = get_elmo_embedding(sentence) # Here assuming sentence is already tokenized\n",
    "        sentence_in = torch.unsqueeze(sentence_in, 1).to(device) \n",
    "        targets = list([tag_to_ix[t] for t in tags])\n",
    "        intent = intent.float().to(device)\n",
    "        pred_i, (entity_score_1, pred_entities) = model(sentence_in)\n",
    "        intent_ICA_1 = get_ICA(pred_i[0], intent) # This will give us the intent classification accuracy\n",
    "        entity_f1_1 = f1_score(targets, pred_entities, average='micro')\n",
    "        entity_score += entity_score_1\n",
    "        entity_f1 += entity_f1_1\n",
    "        intent_ICA += intent_ICA_1\n",
    "        \n",
    "print('Test_ICA: {:.4f}, Test_entity_score: {:.4f}, Test_entity_F1_score: {:.4f}'.format(\n",
    "    intent_ICA/test_samples, entity_score/test_samples, entity_f1/test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
